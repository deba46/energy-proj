{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample BI queries\n",
    "- Trend of daily public net electricity production in Germany for each production type. \n",
    "- Prediction of underperformance of public net electricity on 30min intervals.\n",
    "- Analysis of daily price against the net power for offshore and onshore wind (= production_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import trunc,avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Jar path needed for spark session\n",
    "# For simplicity using locally downloaded jars for delta format\n",
    "cwd = os.getcwd()\n",
    "if cwd.endswith(\"notebooks\"):\n",
    "    proj_dir = os.path.abspath(\"..\")\n",
    "else:\n",
    "    proj_dir = cwd\n",
    "jar_dir = os.path.join(proj_dir, \"jars\")\n",
    "jar1 = os.path.join(jar_dir, \"delta-spark_2.13-4.0.0.jar\")\n",
    "jar2 = os.path.join(jar_dir, \"delta-storage-4.0.0.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "25/07/01 21:14:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"EnergyBI_Insights\") \\\n",
    "            .config(\"spark.jars\", f\"{jar1},{jar2}\") \\\n",
    "            .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "            .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "            .config(\"spark.sql.warehouse.dir\", f\"{proj_dir}/data-warehouse\") \\\n",
    "            .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:/Users/zodenath/Desktop/LOCAL/energy-proj/data-warehouse'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.warehouse.dir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data to SQL warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\" CREATE SCHEMA IF NOT EXISTS energy \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lake_path = f\"{proj_dir}/data/silver/public_power_data\"\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS energy.public_power_data\n",
    "            USING DELTA\n",
    "            LOCATION '{data_lake_path}'\n",
    "\"\"\")\n",
    "\n",
    "price_lake_path = f\"{proj_dir}/data/silver/price_data\"\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS energy.price\n",
    "            USING DELTA\n",
    "            LOCATION '{price_lake_path}'\n",
    "\"\"\")\n",
    "\n",
    "installed_lake_path = f\"{proj_dir}/data/silver/public_power_data\"\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS energy.installed_power_data\n",
    "            USING DELTA\n",
    "            LOCATION '{installed_lake_path}'\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/01 21:15:28 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 8:=================================>                         (4 + 3) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+\n",
      "|      date|     production_type|daily_net_production|\n",
      "+----------+--------------------+--------------------+\n",
      "|2025-06-30|             Biomass|   76155.49926757812|\n",
      "|2025-06-30|Cross border elec...|  145359.10009765625|\n",
      "|2025-06-30|Fossil brown coal...|            185681.0|\n",
      "|2025-06-30|Fossil coal-deriv...|             10088.0|\n",
      "|2025-06-30|          Fossil gas|            183015.0|\n",
      "|2025-06-30|    Fossil hard coal|             81534.0|\n",
      "|2025-06-30|          Fossil oil|              5394.0|\n",
      "|2025-06-30|          Geothermal|   286.9000072479248|\n",
      "|2025-06-30|  Hydro Run-of-River|   37398.59997558594|\n",
      "|2025-06-30|Hydro pumped storage|             79601.0|\n",
      "+----------+--------------------+--------------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Trend of daily public net electricity production in Germany for each production type.\n",
    "\n",
    "daily_trend = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        DATE(timestamp) as date,\n",
    "        production_type,\n",
    "        SUM(net_power_produced) AS daily_net_production\n",
    "    FROM energy.public_power_data\n",
    "    GROUP BY DATE(timestamp), production_type\n",
    "    ORDER BY date, production_type\n",
    "\"\"\")\n",
    "daily_trend.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:===================>                                      (3 + 6) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------------+\n",
      "|     production_type|     interval_start|       interval_end|       total_power|\n",
      "+--------------------+-------------------+-------------------+------------------+\n",
      "|Fossil brown coal...|2025-04-01 00:00:00|2025-04-01 00:30:00|  23208.2998046875|\n",
      "|               Solar|2025-04-01 00:00:00|2025-04-01 00:30:00|               0.0|\n",
      "|Cross border elec...|2025-04-01 00:00:00|2025-04-01 00:30:00|   9019.2001953125|\n",
      "|       Residual load|2025-04-01 00:00:00|2025-04-01 00:30:00|     79468.8984375|\n",
      "|       Wind offshore|2025-04-01 00:00:00|2025-04-01 00:30:00|1679.7999877929688|\n",
      "|        Wind onshore|2025-04-01 00:00:00|2025-04-01 00:30:00|  13683.7001953125|\n",
      "|Hydro pumped storage|2025-04-01 00:00:00|2025-04-01 00:30:00| 659.3000183105469|\n",
      "|          Fossil gas|2025-04-01 00:00:00|2025-04-01 00:30:00|  15752.2001953125|\n",
      "|               Waste|2025-04-01 00:00:00|2025-04-01 00:30:00|            1781.5|\n",
      "|Fossil coal-deriv...|2025-04-01 00:00:00|2025-04-01 00:30:00|1286.3999633789062|\n",
      "+--------------------+-------------------+-------------------+------------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Prediction of underperformance of public net electricity on 30min intervals.\n",
    "unperform_prediction = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        production_type,\n",
    "        window.start AS interval_start,\n",
    "        window.end AS interval_end,\n",
    "        SUM(net_power_produced) AS total_power\n",
    "    FROM (\n",
    "        SELECT *, window(timestamp, '30 minutes') AS window\n",
    "        FROM energy.public_power_data\n",
    "    )\n",
    "    GROUP BY production_type, window\n",
    "    ORDER BY interval_start\n",
    "\"\"\")\n",
    "unperform_prediction.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+-----------------+-----------------+\n",
      "|      date|production_type|      total_power|        avg_price|\n",
      "+----------+---------------+-----------------+-----------------+\n",
      "|2025-06-28|  Wind offshore|92742.40063476562|68.32333257463243|\n",
      "|2025-06-28|   Wind onshore| 221999.998046875|68.32333257463243|\n",
      "|2025-06-29|  Wind offshore|94731.20101928711|42.32374995946884|\n",
      "|2025-06-29|   Wind onshore|         300561.0|42.32374995946884|\n",
      "+----------+---------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analysis of daily price against the net power for offshore and onshore wind (= production_type)\n",
    "\n",
    "price_vs_power = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        DATE(p.timestamp) AS date,\n",
    "        p.production_type,\n",
    "        SUM(p.net_power_produced) AS total_power,\n",
    "        AVG(pr.price) AS avg_price\n",
    "    FROM energy.public_power_data p\n",
    "    JOIN energy.price pr\n",
    "        ON p.timestamp = pr.timestamp\n",
    "    WHERE p.production_type IN ('Wind offshore', 'Wind onshore')\n",
    "    GROUP BY DATE(p.timestamp), p.production_type\n",
    "    ORDER BY date\n",
    "\"\"\")\n",
    "price_vs_power.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Business query : Get monthly avr price and installed capacity\n",
    "# Example of case where we read data directly from silver layer and get business insights\n",
    "price = spark.read.format(\"delta\").load(f\"{proj_dir}/data/silver/price_data\")  \n",
    "installed_power = spark.read.format(\"delta\").load(f\"{proj_dir}/data/silver/installed_power_data\")   \n",
    "\n",
    "price = price.withColumn(\"month_start\", trunc(\"timestamp\", \"month\"))\n",
    "\n",
    "price_monthly = price.withColumn(\"month\", trunc(\"timestamp\", \"month\")) \\\n",
    "                          .groupBy(\"month\") \\\n",
    "                          .agg(avg(\"price\").alias(\"avg_price\"))\n",
    "installed_monthly = installed_power.groupBy(\"date\", \"production_type\") \\\n",
    "                                   .agg(avg(\"installed_power\").alias(\"avg_capacity\"))\n",
    "\n",
    "joined_df = price_monthly.join(\n",
    "    installed_monthly,\n",
    "    price_monthly[\"month\"] == installed_monthly[\"date\"]\n",
    ").drop(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+--------------------+------------------+\n",
      "|     month|        avg_price|     production_type|      avg_capacity|\n",
      "+----------+-----------------+--------------------+------------------+\n",
      "|2025-06-01|200.4925022125244|Battery Storage (...|20.910999298095703|\n",
      "|2025-06-01|200.4925022125244|         Solar gross|107.09200286865234|\n",
      "|2025-06-01|200.4925022125244|        Wind onshore|              NULL|\n",
      "|2025-06-01|200.4925022125244|Battery Storage (...|14.178000450134277|\n",
      "|2025-06-01|200.4925022125244|             Biomass|              NULL|\n",
      "|2025-06-01|200.4925022125244|           Solar net| 95.50800323486328|\n",
      "|2025-06-01|200.4925022125244|       Wind offshore|              NULL|\n",
      "+----------+-----------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ad-hoc analytics without creating tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#public_power = spark.read.format(\"delta\").load(f\"{proj_dir}/data/silver/public_power_data\")  \n",
    "#price = spark.read.format(\"delta\").load(f\"{proj_dir}/data/silver/price_data\")   \n",
    "#installed_power = spark.read.format(\"delta\").load(f\"{proj_dir}/data/silver/installed_power_data\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#public_power.createOrReplaceTempView(\"net_power\")\n",
    "#price.createOrReplaceTempView(\"price\")\n",
    "#installed_power.createOrReplaceTempView(\"installed_power\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
