{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample BI queries\n",
    "- Trend of daily public net electricity production in Germany for each production type. \n",
    "- Prediction of underperformance of public net electricity on 30min intervals.\n",
    "- Analysis of daily price against the net power for offshore and onshore wind (= production_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import trunc,avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Jar path needed for spark session\n",
    "# For simplicity using locally downloaded jars for delta format\n",
    "cwd = os.getcwd()\n",
    "if cwd.endswith(\"notebooks\"):\n",
    "    proj_dir = os.path.abspath(\"..\")\n",
    "else:\n",
    "    proj_dir = cwd\n",
    "jar_dir = os.path.join(proj_dir, \"jars\")\n",
    "jar1 = os.path.join(jar_dir, \"delta-spark_2.13-4.0.0.jar\")\n",
    "jar2 = os.path.join(jar_dir, \"delta-storage-4.0.0.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/01 21:50:19 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"EnergyBI_Insights\") \\\n",
    "            .config(\"spark.jars\", f\"{jar1},{jar2}\") \\\n",
    "            .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "            .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "            .config(\"spark.sql.warehouse.dir\", f\"{proj_dir}/data-warehouse\") \\\n",
    "            .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:/Users/zodenath/Desktop/LOCAL/energy-proj/data-warehouse'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.warehouse.dir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data to SQL warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\" CREATE SCHEMA IF NOT EXISTS energy \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lake_path = f\"{proj_dir}/data/silver/public_power_data\"\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS energy.public_power_data\n",
    "            USING DELTA\n",
    "            LOCATION '{data_lake_path}'\n",
    "\"\"\")\n",
    "\n",
    "price_lake_path = f\"{proj_dir}/data/silver/price_data\"\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS energy.price\n",
    "            USING DELTA\n",
    "            LOCATION '{price_lake_path}'\n",
    "\"\"\")\n",
    "\n",
    "installed_lake_path = f\"{proj_dir}/data/silver/public_power_data\"\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS energy.installed_power_data\n",
    "            USING DELTA\n",
    "            LOCATION '{installed_lake_path}'\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+----------------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                                   |comment|\n",
      "+----------------------------+----------------------------------------------------------------------------+-------+\n",
      "|production_type             |string                                                                      |NULL   |\n",
      "|net_power_produced          |float                                                                       |NULL   |\n",
      "|timestamp                   |timestamp                                                                   |NULL   |\n",
      "|# Partition Information     |                                                                            |       |\n",
      "|# col_name                  |data_type                                                                   |comment|\n",
      "|production_type             |string                                                                      |NULL   |\n",
      "|                            |                                                                            |       |\n",
      "|# Detailed Table Information|                                                                            |       |\n",
      "|Name                        |spark_catalog.energy.public_power_data                                      |       |\n",
      "|Type                        |EXTERNAL                                                                    |       |\n",
      "|Location                    |file:/Users/zodenath/Desktop/LOCAL/energy-proj/data/silver/public_power_data|       |\n",
      "|Provider                    |delta                                                                       |       |\n",
      "|Table Properties            |[delta.minReaderVersion=1,delta.minWriterVersion=2]                         |       |\n",
      "+----------------------------+----------------------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE FORMATTED energy.public_power_data\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+\n",
      "|      date|     production_type|daily_net_production|\n",
      "+----------+--------------------+--------------------+\n",
      "|2025-06-30|             Biomass|   76155.49926757812|\n",
      "|2025-06-30|Cross border elec...|  145359.10009765625|\n",
      "|2025-06-30|Fossil brown coal...|            185681.0|\n",
      "|2025-06-30|Fossil coal-deriv...|             10088.0|\n",
      "|2025-06-30|          Fossil gas|            183015.0|\n",
      "|2025-06-30|    Fossil hard coal|             81534.0|\n",
      "|2025-06-30|          Fossil oil|              5394.0|\n",
      "|2025-06-30|          Geothermal|   286.9000072479248|\n",
      "|2025-06-30|  Hydro Run-of-River|   37398.59997558594|\n",
      "|2025-06-30|Hydro pumped storage|             79601.0|\n",
      "+----------+--------------------+--------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Trend of daily public net electricity production in Germany for each production type.\n",
    "\n",
    "daily_trend = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        DATE(timestamp) as date,\n",
    "        production_type,\n",
    "        SUM(net_power_produced) AS daily_net_production\n",
    "    FROM energy.public_power_data\n",
    "    GROUP BY DATE(timestamp), production_type\n",
    "    ORDER BY date, production_type\n",
    "\"\"\")\n",
    "daily_trend.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+-----------------+\n",
      "|     production_type|     interval_start|       interval_end|      total_power|\n",
      "+--------------------+-------------------+-------------------+-----------------+\n",
      "|       Residual load|2025-06-30 19:00:00|2025-06-30 19:30:00|          45144.0|\n",
      "|               Waste|2025-06-30 19:00:00|2025-06-30 19:30:00|727.4000244140625|\n",
      "|          Fossil gas|2025-06-30 19:00:00|2025-06-30 19:30:00|           9320.0|\n",
      "|Fossil coal-deriv...|2025-06-30 19:00:00|2025-06-30 19:30:00|            441.0|\n",
      "|                Load|2025-06-30 19:00:00|2025-06-30 19:30:00|          57476.0|\n",
      "|             Biomass|2025-06-30 19:00:00|2025-06-30 19:30:00|3972.699951171875|\n",
      "|    Fossil hard coal|2025-06-30 19:00:00|2025-06-30 19:30:00|           4204.0|\n",
      "|        Wind onshore|2025-06-30 19:00:00|2025-06-30 19:30:00|           2062.0|\n",
      "|Hydro pumped storage|2025-06-30 19:00:00|2025-06-30 19:30:00|           4033.0|\n",
      "|Renewable share o...|2025-06-30 19:00:00|2025-06-30 19:30:00|             40.5|\n",
      "+--------------------+-------------------+-------------------+-----------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Prediction of underperformance of public net electricity on 30min intervals.\n",
    "unperform_prediction = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        production_type,\n",
    "        window.start AS interval_start,\n",
    "        window.end AS interval_end,\n",
    "        SUM(net_power_produced) AS total_power\n",
    "    FROM (\n",
    "        SELECT *, window(timestamp, '30 minutes') AS window\n",
    "        FROM energy.public_power_data\n",
    "    )\n",
    "    GROUP BY production_type, window\n",
    "    ORDER BY interval_start\n",
    "\"\"\")\n",
    "unperform_prediction.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+-----------+------------------+\n",
      "|      date|production_type|total_power|         avg_price|\n",
      "+----------+---------------+-----------+------------------+\n",
      "|2025-06-30|   Wind onshore|    22370.0| 200.4925022125244|\n",
      "|2025-06-30|  Wind offshore|     5542.0| 200.4925022125244|\n",
      "|2025-07-01|   Wind onshore|    96261.0|102.00449981689454|\n",
      "|2025-07-01|  Wind offshore|    28365.0|102.00449981689454|\n",
      "+----------+---------------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analysis of daily price against the net power for offshore and onshore wind (= production_type)\n",
    "\n",
    "price_vs_power = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        DATE(p.timestamp) AS date,\n",
    "        p.production_type,\n",
    "        SUM(p.net_power_produced) AS total_power,\n",
    "        AVG(pr.price) AS avg_price\n",
    "    FROM energy.public_power_data p\n",
    "    JOIN energy.price pr\n",
    "        ON p.timestamp = pr.timestamp\n",
    "    WHERE p.production_type IN ('Wind offshore', 'Wind onshore')\n",
    "    GROUP BY DATE(p.timestamp), p.production_type\n",
    "    ORDER BY date\n",
    "\"\"\")\n",
    "price_vs_power.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ad-hoc analytics by reading data from silver layer and processing further\n",
    "- Read data from silver layer ; modify accoriding to need \n",
    "- Load to warehouse in a table (managed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Business query : Get monthly avr price and installed capacity\n",
    "# Example of case where we read data directly from silver layer and get business insights\n",
    "price = spark.read.format(\"delta\").load(f\"{proj_dir}/data/silver/price_data\")  \n",
    "installed_power = spark.read.format(\"delta\").load(f\"{proj_dir}/data/silver/installed_power_data\")   \n",
    "\n",
    "price_monthly = price.withColumn(\"month\", trunc(\"timestamp\", \"month\")) \\\n",
    "                          .groupBy(\"month\") \\\n",
    "                          .agg(avg(\"price\").alias(\"avg_price\"))\n",
    "installed_monthly = installed_power.groupBy(\"date\", \"production_type\") \\\n",
    "                                   .agg(avg(\"installed_power\").alias(\"avg_capacity\"))\n",
    "\n",
    "joined_df = price_monthly.join(\n",
    "    installed_monthly,\n",
    "    price_monthly[\"month\"] == installed_monthly[\"date\"]\n",
    ").drop(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+--------------------+------------------+\n",
      "|     month|        avg_price|     production_type|      avg_capacity|\n",
      "+----------+-----------------+--------------------+------------------+\n",
      "|2025-06-01|200.4925022125244|Battery Storage (...|20.910999298095703|\n",
      "|2025-06-01|200.4925022125244|         Solar gross|107.09200286865234|\n",
      "|2025-06-01|200.4925022125244|        Wind onshore|              NULL|\n",
      "|2025-06-01|200.4925022125244|Battery Storage (...|14.178000450134277|\n",
      "|2025-06-01|200.4925022125244|             Biomass|              NULL|\n",
      "|2025-06-01|200.4925022125244|           Solar net| 95.50800323486328|\n",
      "|2025-06-01|200.4925022125244|       Wind offshore|              NULL|\n",
      "+----------+-----------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all tbales in DW\n",
    "spark.sql(\"SHOW TABLES IN energy\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
