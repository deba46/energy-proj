{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef5e9691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T17:21:46.819681Z",
     "iopub.status.busy": "2025-06-29T17:21:46.819300Z",
     "iopub.status.idle": "2025-06-29T17:21:46.830708Z",
     "shell.execute_reply": "2025-06-29T17:21:46.830140Z"
    },
    "papermill": {
     "duration": 0.021226,
     "end_time": "2025-06-29T17:21:46.832302",
     "exception": false,
     "start_time": "2025-06-29T17:21:46.811076",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "days = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971dcf46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T17:21:46.863710Z",
     "iopub.status.busy": "2025-06-29T17:21:46.863427Z",
     "iopub.status.idle": "2025-06-29T17:21:46.866103Z",
     "shell.execute_reply": "2025-06-29T17:21:46.865630Z"
    },
    "papermill": {
     "duration": 0.012991,
     "end_time": "2025-06-29T17:21:46.867272",
     "exception": false,
     "start_time": "2025-06-29T17:21:46.854281",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "days = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "145e76fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T17:21:46.882100Z",
     "iopub.status.busy": "2025-06-29T17:21:46.881774Z",
     "iopub.status.idle": "2025-06-29T17:21:47.147439Z",
     "shell.execute_reply": "2025-06-29T17:21:47.147105Z"
    },
    "papermill": {
     "duration": 0.272886,
     "end_time": "2025-06-29T17:21:47.148393",
     "exception": false,
     "start_time": "2025-06-29T17:21:46.875507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, posexplode, col, size,to_date, concat_ws, lit\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, BooleanType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de8754f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T17:21:47.171567Z",
     "iopub.status.busy": "2025-06-29T17:21:47.171412Z",
     "iopub.status.idle": "2025-06-29T17:21:47.173489Z",
     "shell.execute_reply": "2025-06-29T17:21:47.173183Z"
    },
    "papermill": {
     "duration": 0.012896,
     "end_time": "2025-06-29T17:21:47.174236",
     "exception": false,
     "start_time": "2025-06-29T17:21:47.161340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"JAVA_HOME\"] = \"/opt/homebrew/opt/openjdk@17/libexec/openjdk.jdk/Contents/Home\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1110ad2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T17:21:47.192608Z",
     "iopub.status.busy": "2025-06-29T17:21:47.192474Z",
     "iopub.status.idle": "2025-06-29T17:21:47.194654Z",
     "shell.execute_reply": "2025-06-29T17:21:47.194423Z"
    },
    "papermill": {
     "duration": 0.007366,
     "end_time": "2025-06-29T17:21:47.195326",
     "exception": false,
     "start_time": "2025-06-29T17:21:47.187960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get Jar path needed for spark session\n",
    "# For simplicity using locally downloaded jars for delta format\n",
    "cwd = os.getcwd()\n",
    "if cwd.endswith(\"notebooks\"):\n",
    "    proj_dir = os.path.abspath(\"..\")\n",
    "else:\n",
    "    proj_dir = cwd\n",
    "jar_dir = os.path.join(proj_dir, \"jars\")\n",
    "jar1 = os.path.join(jar_dir, \"delta-spark_2.13-4.0.0.jar\")\n",
    "jar2 = os.path.join(jar_dir, \"delta-storage-4.0.0.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e2b2a21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T17:21:47.206318Z",
     "iopub.status.busy": "2025-06-29T17:21:47.206180Z",
     "iopub.status.idle": "2025-06-29T17:21:55.604222Z",
     "shell.execute_reply": "2025-06-29T17:21:55.603922Z"
    },
    "papermill": {
     "duration": 8.405426,
     "end_time": "2025-06-29T17:21:55.605097",
     "exception": false,
     "start_time": "2025-06-29T17:21:47.199671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/29 19:21:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"EnergyUseCase\") \\\n",
    "            .config(\"spark.jars\", f\"{jar1},{jar2}\") \\\n",
    "            .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "            .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "            .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbece877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T17:21:55.621629Z",
     "iopub.status.busy": "2025-06-29T17:21:55.621439Z",
     "iopub.status.idle": "2025-06-29T17:21:55.623489Z",
     "shell.execute_reply": "2025-06-29T17:21:55.623260Z"
    },
    "papermill": {
     "duration": 0.016936,
     "end_time": "2025-06-29T17:21:55.624142",
     "exception": false,
     "start_time": "2025-06-29T17:21:55.607206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# API Configuration\n",
    "BASE_URL = \"https://api.energy-charts.info\"\n",
    "ENDPOINT_CONFIG = { \n",
    "    \"installed_power\": {\n",
    "        \"path\": \"/installed_power\",\n",
    "        \"params\": [\"country\", \"time_step\", \"installation_decommission\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74caa150",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T17:21:55.640143Z",
     "iopub.status.busy": "2025-06-29T17:21:55.640009Z",
     "iopub.status.idle": "2025-06-29T17:21:55.641924Z",
     "shell.execute_reply": "2025-06-29T17:21:55.641679Z"
    },
    "papermill": {
     "duration": 0.008768,
     "end_time": "2025-06-29T17:21:55.642773",
     "exception": false,
     "start_time": "2025-06-29T17:21:55.634005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pipeline Parameters\n",
    "country= \"de\"\n",
    "time_step = \"monthly\"\n",
    "#start_time = \"2025-04-01 00:00\"\n",
    "#end_time = \"2025-04-30 00:00\"\n",
    "end_time = datetime.now(timezone.utc)\n",
    "start_time = end_time - timedelta(days=days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11b64ca2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T17:21:55.659254Z",
     "iopub.status.busy": "2025-06-29T17:21:55.659121Z",
     "iopub.status.idle": "2025-06-29T17:21:55.662357Z",
     "shell.execute_reply": "2025-06-29T17:21:55.662088Z"
    },
    "papermill": {
     "duration": 0.016478,
     "end_time": "2025-06-29T17:21:55.663101",
     "exception": false,
     "start_time": "2025-06-29T17:21:55.646623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fetch_api_data(endpoint_name, **kwargs):\n",
    "    \"\"\"\n",
    "    Fetch JSON data from the energy charts \n",
    "    \"\"\"\n",
    "\n",
    "    if endpoint_name not in ENDPOINT_CONFIG:\n",
    "        raise ValueError(f\"Unsupported endpoint: {endpoint_name}\")\n",
    "    \n",
    "    config = ENDPOINT_CONFIG[endpoint_name]\n",
    "    path = config[\"path\"]\n",
    "    required_params = config[\"params\"]\n",
    "    missing = [p for p in required_params if p not in kwargs]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required params: {missing} for endpoint '{endpoint_name}'\")\n",
    "    params = {k: v for k, v in kwargs.items() if k in required_params}\n",
    "    url = f\"{BASE_URL}{path}\"\n",
    "    try:\n",
    "        print(f\"Fetching data from api with these params - {params}\")\n",
    "        response = requests.get(url, params=params, verify=False)\n",
    "        print(f\"Status Code: {response.status_code}\")\n",
    "        data = response.json() \n",
    "        if not data:\n",
    "            print(\"Empty response received.\")\n",
    "            return None\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab2acb8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T17:21:55.669385Z",
     "iopub.status.busy": "2025-06-29T17:21:55.669267Z",
     "iopub.status.idle": "2025-06-29T17:21:58.296291Z",
     "shell.execute_reply": "2025-06-29T17:21:58.296035Z"
    },
    "papermill": {
     "duration": 2.632792,
     "end_time": "2025-06-29T17:21:58.297428",
     "exception": false,
     "start_time": "2025-06-29T17:21:55.664636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from api with these params - {'country': 'de', 'time_step': 'monthly', 'installation_decommission': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/energy/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.energy-charts.info'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+\n",
      "|                time|    production_types|deprecated|\n",
      "+--------------------+--------------------+----------+\n",
      "|[01.2002, 02.2002...|[{Biomass, [0.0, ...|     false|\n",
      "+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetch installed power\n",
    "installed_power = fetch_api_data(\"installed_power\",\n",
    "                            country=country,\n",
    "                            time_step=time_step,  \n",
    "                           installation_decommission=False\n",
    "                        )\n",
    "# Create raw dataframe \n",
    "if installed_power is not None and isinstance(installed_power, dict):\n",
    "    # Define schema\n",
    "    installed_power_schema = StructType([\n",
    "        StructField(\"time\", ArrayType(StringType()), True),\n",
    "        StructField(\"production_types\", ArrayType(\n",
    "            StructType([\n",
    "                StructField(\"name\", StringType(), True),\n",
    "                StructField(\"data\", ArrayType(FloatType()), True)\n",
    "            ])\n",
    "        ), True),\n",
    "        StructField(\"deprecated\", BooleanType(), True)\n",
    "    ])\n",
    "    installed_power_df = spark.createDataFrame([installed_power], schema=installed_power_schema)\n",
    "    installed_power_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c2ce089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T17:21:58.310563Z",
     "iopub.status.busy": "2025-06-29T17:21:58.310437Z",
     "iopub.status.idle": "2025-06-29T17:22:02.699794Z",
     "shell.execute_reply": "2025-06-29T17:22:02.699524Z"
    },
    "papermill": {
     "duration": 4.401129,
     "end_time": "2025-06-29T17:22:02.700595",
     "exception": false,
     "start_time": "2025-06-29T17:21:58.299466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 5:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/29 19:22:01 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8:==================================================>      (44 + 6) / 50]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+---------------+\n",
      "|      date|     production_type|installed_power|\n",
      "+----------+--------------------+---------------+\n",
      "|2025-05-01|Battery Storage (...|         20.537|\n",
      "|2025-05-01|Battery Storage (...|         13.961|\n",
      "|2025-05-01|         Solar gross|        106.399|\n",
      "|2025-05-01|             Biomass|          9.202|\n",
      "|2025-05-01|           Solar net|         94.911|\n",
      "|2025-05-01|       Wind offshore|          9.215|\n",
      "|2025-05-01|        Wind onshore|          65.04|\n",
      "+----------+--------------------+---------------+\n",
      "\n",
      "root\n",
      " |-- date: date (nullable = false)\n",
      " |-- production_type: string (nullable = true)\n",
      " |-- installed_power: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "installed_power_df = installed_power_df.withColumn(\"production_type\", explode(\"production_types\"))\n",
    "installed_power_df = installed_power_df.select(\n",
    "    col(\"time\"),\n",
    "    col(\"production_type.name\").alias(\"production_type\"),\n",
    "    posexplode(col(\"production_type.data\")).alias(\"pos\", \"value\")\n",
    ")\n",
    "installed_power_df = installed_power_df.filter(col(\"pos\") < size(col(\"time\")))\n",
    "installed_power_df = installed_power_df.withColumn(\"monthyear\", col(\"time\")[col(\"pos\")]).drop(\"time\")\n",
    "# Format date filed        \n",
    "installed_power_df = installed_power_df.withColumn(\"date\", to_date(concat_ws(\"-\", lit(\"01\"), col(\"monthyear\")), \"dd-MM.yyyy\") )\n",
    "\n",
    "# Filter dataframe to get required data based on start and end time\n",
    "start_year, start_month = start_time.year, start_time.month\n",
    "end_year, end_month = start_time.year, start_time.month\n",
    "start_filter = to_date(lit(f\"{start_year}-{start_month}-01\"))\n",
    "end_filter = to_date(lit(f\"{end_year}-{end_month}-01\"))\n",
    "if start_year == end_year and start_month == end_month:\n",
    "    filtered = installed_power_df.filter(col(\"date\") == start_filter)\n",
    "else:\n",
    "    filtered = installed_power_df.filter((col(\"date\") >= start_filter) & (col(\"date\") <= end_filter))\n",
    "\n",
    "installed_power_data = filtered.select(\"date\", \n",
    "                                        \"production_type\", \n",
    "                                        col(\"value\").alias(\"installed_power\")).drop(\"monthyear\")\n",
    "installed_power_data = installed_power_data.dropDuplicates() \n",
    "# Write to storage in Delta format\n",
    "installed_power_data.write \\\n",
    "                    .format(\"delta\") \\\n",
    "                    .mode(\"append\") \\\n",
    "                    .option(\"mergeSchema\", \"true\") \\\n",
    "                    .partitionBy(\"date\") \\\n",
    "                    .save(f\"{proj_dir}/data/silver/installed_power_data\")  \n",
    "\n",
    "installed_power_data.show(10)\n",
    "installed_power_data.printSchema()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.252744,
   "end_time": "2025-06-29T17:22:04.440790",
   "environment_variables": {},
   "exception": null,
   "input_path": "/Users/zodenath/Desktop/projects/energy-proj/notebooks/monthly_ingest.ipynb",
   "output_path": "/Users/zodenath/Desktop/projects/energy-proj/output/out_monthly_2025-06-29.ipynb",
   "parameters": {
    "days": 30
   },
   "start_time": "2025-06-29T17:21:45.188046",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}